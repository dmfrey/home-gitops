---
# yaml-language-server: $schema=https://raw.githubusercontent.com/budimanjojo/talhelper/master/pkg/config/schemas/talconfig.json
clusterName: ${CLUSTER_NAME}

# renovate: depName=ghcr.io/siderolabs/installer datasource=docker extractVersion=^(?<version>.*)$
talosVersion: v1.9.4
# renovate: datasource=github-releases extractVersion=^v(?<version>.*)$ depName=kubernetes/kubernetes
kubernetesVersion: 1.32.2

endpoint: "https://${CLUSTER_NAME}.${INTERNAL_DOMAIN}:6443"

allowSchedulingOnControlPlanes: true

clusterPodNets:
  - 172.22.0.0/16
clusterSvcNets:
  - 172.23.0.0/16

cniConfig:
  name: none

additionalApiServerCertSans: &san
  - ${CLUSTER_ENDPOINT_IP}
  - ${CLUSTER_NAME}.${INTERNAL_DOMAIN}
  - ${EXTERNAL_CLUSTER_NAME}.${EXTERNAL_DOMAIN}
  - "127.0.0.1" # KubePrism

additionalMachineCertSans: *san

nodes:

  # GEEKOM A5 Mini / AMD Ryzen 7 5800H / 64GB / 240GB SSD / 2TB Nvme
  - hostname: dmf-amd-001
    controlPlane: true
    ipAddress: 192.168.30.31
    installDiskSelector:
      model: GIGASTONE SSD 51
    disableSearchDomain: true
    networkInterfaces: &networkInterfaces-amd
      - interface: eth0   # enp2s0
        dhcp: false
        mtu: 1500
        vlans:
          - vlanId: 30
            mtu: 1500
            dhcp: true
            dhcpOptions:
              routeMetric: 1024
            vip:
              ip: ${CLUSTER_ENDPOINT_IP}
          - vlanId: 50
            mtu: 1500
            dhcp: true
            dhcpOptions:
              routeMetric: 4096
    talosImageURL: &factory-amd factory.talos.dev/installer/b51b7b6129e8ba285ab83ef1059418c434de4223a7ae4b3905dd06512b923943
    nodeLabels: &nodeLabels-amd
      topology.kubernetes.io/region: dmf
      topology.kubernetes.io/zone: dmf-u
      # Needed because Labels are limited to 63 Characters
      factory.talos.dev/schematic-prefix: b51b7b6129e8ba285ab83ef1059418c4  # 323dba38c87ba0d379a6f706ae691ba9
      factory.talos.dev/schematic-suffix: 34de4223a7ae4b3905dd06512b923943  # 50025ed87869a89325321f1eff050067
    extensionServices: &extensionServices
      - name: nut-client
        configFiles:
          - content: |
              MONITOR qnapups@${NAS_SERVER} 1 ${NUT_USER} ${NUT_PASSWORD} slave
              SHUTDOWNCMD "/sbin/poweroff"
            mountPath: /usr/local/etc/nut/upsmon.conf

  # GEEKOM A5 Mini / AMD Ryzen 7 5800H / 64GB / 512GB SSD / 2TB Nvme
  - hostname: dmf-amd-002
    controlPlane: true
    ipAddress: 192.168.30.32
    installDiskSelector:
      model: Gigastone SSD
    disableSearchDomain: true
    networkInterfaces: *networkInterfaces-amd
    talosImageURL: *factory-amd
    nodeLabels: *nodeLabels-amd
    extensionServices: *extensionServices

  # GEEKOM A5 Mini / AMD Ryzen 7 5800H / 64GB / 240GB SSD / 2TB Nvme
  - hostname: dmf-amd-003
    controlPlane: true
    ipAddress: 192.168.30.33
    installDiskSelector:
      model: Gigastone SSD
    disableSearchDomain: true
    networkInterfaces: *networkInterfaces-amd
    talosImageURL: *factory-amd
    nodeLabels: *nodeLabels-amd
    extensionServices: *extensionServices

  # GEEKOM Mini IT 13 / Intel UHD Graphics / 64GB / 512GB SSD / 2TB Nvme
  - hostname: dmf-intel-001
    controlPlane: false
    ipAddress: 192.168.30.41
    installDiskSelector:
      model: GIGASTONE SSD 51
    disableSearchDomain: true
    networkInterfaces: &networkInterfaces-intel
      - interface: eth0   # enp87s0
        dhcp: false
        mtu: 1500
        vlans:
          - vlanId: 30
            mtu: 1500
            dhcp: true
            dhcpOptions:
              routeMetric: 1024
          - vlanId: 50
            mtu: 1500
            dhcp: true
            dhcpOptions:
              routeMetric: 4096
    talosImageURL: &factory-intel factory.talos.dev/installer/deee80e4ca4ed205ba87d67b33af7b023264d01ac97c1ce13ab083e6d70074f0
    nodeLabels: &nodeLabels-intel
      topology.kubernetes.io/region: dmf
      topology.kubernetes.io/zone: dmf-u
      # Needed because Labels are limited to 63 Characters
      factory.talos.dev/schematic-prefix: deee80e4ca4ed205ba87d67b33af7b02  # 8a71f9fe5c25403801ac19ff2beeacbf
      factory.talos.dev/schematic-suffix: 3264d01ac97c1ce13ab083e6d70074f0  # 79bcfaf82405833d75707ede0968c64d
    extensionServices: *extensionServices

  # GEEKOM Mini IT 13 / Intel Iris Xe Graphics / 64GB / 512GB SSD / 2TB Nvme
  - hostname: dmf-intel-002
    controlPlane: false
    ipAddress: 192.168.30.42
    installDiskSelector:
      model: GIGASTONE SSD 51
    disableSearchDomain: true
    networkInterfaces: *networkInterfaces-intel
    talosImageURL: *factory-intel
    nodeLabels: *nodeLabels-intel
    extensionServices: *extensionServices

controlPlane:
  schematic:
    customization:
      extraKernelArgs:
        - net.ifnames=0
        - apparmor=0                          # Less security, faster puter
        - init_on_alloc=0                     # Less security, faster puter
        - init_on_free=0                      # Less security, faster puter
        # - iommu=pt                            # PCI Passthrough
        - mitigations=off                     # Less security, faster puter
        - security=none                       # Less security, faster puter
        - talos.auditd.disabled=1             # Less security, faster puter
      systemExtensions:
        officialExtensions:
          - siderolabs/amd-ucode
          - siderolabs/amdgpu
          - siderolabs/nut-client

  patches:

    # Configure containerd
    - |-
      machine:
        files:
          - op: create
            path: /etc/cri/conf.d/20-customization.part
            content: |-
              [plugins."io.containerd.cri.v1.images"]
                discard_unpacked_layers = false
              # [plugins."io.containerd.grpc.v1.cri"]
              #   enable_unprivileged_ports = true
              #   enable_unprivileged_icmp = true
              # [plugins."io.containerd.grpc.v1.cri".containerd]
              #   discard_unpacked_layers = false
              # [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
              #   discard_unpacked_layers = false
          - op: overwrite
            path: /etc/nfsmount.conf
            permissions: 0o644
            content: |
              [ NFSMount_Global_Options ]
              nfsvers=4.1
              hard=True
              nconnect=16
              noatime=True

    # Disable search domain everywhere
    - |-
      machine:
        network:
          disableSearchDomain: true

    # Configure kubelet
    - |-
      machine:
        kubelet:
          # extraArgs:
          #   feature-gates: GracefulNodeShutdown=true
          #   rotate-server-certificates: true
          extraConfig:
            maxPods: 250
          # extraMounts:
          #   - destination: /var/mnt/extra
          #     type: bind
          #     source: /var/mnt/extra
          #     options: ["bind", "rshared", "rw"]
          nodeIP:
            validSubnets:
              - 192.168.30.0/24

    # Enable KubePrism
    - |-
      machine:
        features:
          kubePrism:
            enabled: true
            port: 7445

    # Force nameserver
    # - |-
    #   machine:
    #     network:
    #       nameservers:
    #         - ${DNS_SERVER}

    # Configure NTP
    - |-
      machine:
        time:
          disabled: false
          servers:
            - ${NTP_SERVER}

    # Static host entries
    - |-
      machine:
        network:
          extraHostEntries:
            - ip: ${CLUSTER_ENDPOINT_IP}
              aliases:
                - ${CLUSTER_NAME}.${INTERNAL_DOMAIN}
            - ip: ${CLUSTER_ENDPOINT_IP}
              aliases:
                - ${EXTERNAL_CLUSTER_NAME}.${EXTERNAL_DOMAIN}

    # Custom sysctl settings
    - |-
      machine:
        sysctls:
          fs.inotify.max_user_watches: 1048576   # Watchdog
          fs.inotify.max_user_instances: 8192    # Watchdog
          # net.core.netdev_max_backlog: 30000
          net.core.default_qdisc: fq             # 10Gb/s
          net.core.rmem_max: 67108864            # 10Gb/s | Cloudflared / QUIC
          net.core.wmem_max: 67108864            # 10Gb/s | Cloudflared / QUIC
          net.ipv4.tcp_congestion_control: bbr   # 10Gb/s
          net.ipv4.tcp_fastopen: 3               # Send and accept data in the opening SYN packet
          net.ipv4.tcp_mtu_probing: 1            # 10Gb/s | Jumbo frames
          net.ipv4.tcp_rmem: 4096 87380 33554432 # 10Gb/s
          net.ipv4.tcp_wmem: 4096 65536 33554432 # 10Gb/s
          net.ipv4.tcp_window_scaling: 1         # 10Gb/s
          # net.ipv4.tcp_tw_reuse: 1
          vm.nr_hugepages: 1024                  # PostgreSQL

    # Custom sysfs
    - |-
      machine:
        sysfs:
          devices.system.cpu.cpu0.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu1.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu2.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu3.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu4.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu5.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu6.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu7.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu8.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu9.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu10.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu11.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu12.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu13.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu14.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu15.cpufreq.energy_performance_preference: balance_performance

    # Various udev rules
    - |-
      machine:
        udev:
          rules:
            - KERNEL=="ttyUSB[0-9]", GROUP="20", MODE="0660"
            - KERNEL=="kfd", MODE="0666" SUBSYSTEM=="drm"
            - KERNEL=="renderD*", MODE="0666"

    # Kernel configuration
    - |-
      machine:
        kernel:
          modules:
            - name: nbd

    # Cluster configuration
    - |-
      cluster:
        allowSchedulingOnMasters: true
        apiServer:
          extraArgs:
            enable-aggregator-routing: true
            feature-gates: MutatingAdmissionPolicy=true
            runtime-config: admissionregistration.k8s.io/v1alpha1=true
        controllerManager:
          extraArgs:
            bind-address: 0.0.0.0
        extraManifests:
          # - # renovate: datasource=github-releases depName=prometheus-operator/prometheus-operator
          - https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.81.0/example/prometheus-operator-crd/monitoring.coreos.com_alertmanagerconfigs.yaml
          # - # renovate: datasource=github-releases depName=prometheus-operator/prometheus-operator
          - https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.81.0/example/prometheus-operator-crd/monitoring.coreos.com_alertmanagers.yaml
          # - # renovate: datasource=github-releases depName=prometheus-operator/prometheus-operator
          - https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.81.0/example/prometheus-operator-crd/monitoring.coreos.com_podmonitors.yaml
          # - # renovate: datasource=github-releases depName=prometheus-operator/prometheus-operator
          - https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.81.0/example/prometheus-operator-crd/monitoring.coreos.com_probes.yaml
          # - # renovate: datasource=github-releases depName=prometheus-operator/prometheus-operator
          - https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.81.0/example/prometheus-operator-crd/monitoring.coreos.com_prometheusagents.yaml
          # - # renovate: datasource=github-releases depName=prometheus-operator/prometheus-operator
          - https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.81.0/example/prometheus-operator-crd/monitoring.coreos.com_prometheuses.yaml
          # - # renovate: datasource=github-releases depName=prometheus-operator/prometheus-operator
          - https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.81.0/example/prometheus-operator-crd/monitoring.coreos.com_prometheusrules.yaml
          # - # renovate: datasource=github-releases depName=prometheus-operator/prometheus-operator
          - https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.81.0/example/prometheus-operator-crd/monitoring.coreos.com_scrapeconfigs.yaml
          # - # renovate: datasource=github-releases depName=prometheus-operator/prometheus-operator
          - https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.81.0/example/prometheus-operator-crd/monitoring.coreos.com_servicemonitors.yaml
          # - # renovate: datasource=github-releases depName=prometheus-operator/prometheus-operator
          - https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.81.0/example/prometheus-operator-crd/monitoring.coreos.com_thanosrulers.yaml

        proxy:
          disabled: true
        scheduler:
          extraArgs:
            bind-address: 0.0.0.0

    # ETCD configuration
    - |-
      cluster:
        etcd:
          extraArgs:
            listen-metrics-urls: http://0.0.0.0:2381
          advertisedSubnets:
            - 192.168.30.0/24

    # Disable default API server admission plugins.
    - |-
      - op: remove
        path: /cluster/apiServer/admissionControl

    # Enable K8s Talos API Access
    - |-
      machine:
        features:
          rbac: true
          stableHostname: true
          kubernetesTalosAPIAccess:
            enabled: true
            allowedRoles:
              - os:admin
            allowedKubernetesNamespaces:
              - system
          apidCheckExtKeyUsage: true
          diskQuotaSupport: true
          hostDNS:
            enabled: true
            resolveMemberNames: true
            forwardKubeDNSToHost: false # Incompatible with Cilium bpf masquerade

worker:
  schematic:
    customization:
      extraKernelArgs:
        - net.ifnames=0
        - i915.enable_guc=3                   # Raptor Lake CPU / iGPU
        - apparmor=0                          # Less security, faster puter
        - init_on_alloc=0                     # Less security, faster puter
        - init_on_free=0                      # Less security, faster puter
        - intel_iommu=on                      # PCI Passthrough
        - iommu=pt                            # PCI Passthrough
        - mitigations=off                     # Less security, faster puter
        # - module_blacklist=igc                # Disable onboard NIC
        - security=none                       # Less security, faster puter
        - sysctl.kernel.kexec_load_disabled=1 # Raptor Lake CPU / iGPU
        - talos.auditd.disabled=1             # Less security, faster puter
      systemExtensions:
        officialExtensions:
          - siderolabs/i915
          - siderolabs/intel-ucode
          - siderolabs/mei
          - siderolabs/nut-client

  patches:

    # Configure containerd
    - |-
      machine:
        files:
          - op: create
            path: /etc/cri/conf.d/20-customization.part
            content: |-
              [plugins."io.containerd.cri.v1.images"]
                discard_unpacked_layers = false
              # [plugins."io.containerd.grpc.v1.cri"]
              #   enable_unprivileged_ports = true
              #   enable_unprivileged_icmp = true
              # [plugins."io.containerd.grpc.v1.cri".containerd]
              #   discard_unpacked_layers = false
              # [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
              #   discard_unpacked_layers = false
          - op: overwrite
            path: /etc/nfsmount.conf
            permissions: 0o644
            content: |
              [ NFSMount_Global_Options ]
              nfsvers=4.1
              hard=True
              nconnect=16
              noatime=True

    # Disable search domain everywhere
    - |-
      machine:
        network:
          disableSearchDomain: true

    # Configure kubelet
    - |-
      machine:
        kubelet:
          # extraArgs:
          #   feature-gates: GracefulNodeShutdown=true
          #   rotate-server-certificates: true
          extraConfig:
            maxPods: 250
          # extraMounts:
          #   - destination: /var/mnt/extra
          #     type: bind
          #     source: /var/mnt/extra
          #     options: ["bind", "rshared", "rw"]
          defaultRuntimeSeccompProfileEnabled: true
          nodeIP:
            validSubnets:
              - 192.168.30.0/24

    # Enable KubePrism
    - |-
      machine:
        features:
          kubePrism:
            enabled: true
            port: 7445

    # Force nameserver
    # - |-
    #   machine:
    #     network:
    #       nameservers:
    #         - ${DNS_SERVER}

    # Configure NTP
    - |-
      machine:
        time:
          disabled: false
          servers:
            - ${NTP_SERVER}

    # Custom sysctl settings
    - |-
      machine:
        sysctls:
          fs.inotify.max_user_watches: 1048576   # Watchdog
          fs.inotify.max_user_instances: 8192    # Watchdog
          # net.core.netdev_max_backlog: 30000
          net.core.default_qdisc: fq             # 10Gb/s
          net.core.rmem_max: 67108864            # 10Gb/s | Cloudflared / QUIC
          net.core.wmem_max: 67108864            # 10Gb/s | Cloudflared / QUIC
          net.ipv4.tcp_congestion_control: bbr   # 10Gb/s
          net.ipv4.tcp_fastopen: 3               # Send and accept data in the opening SYN packet
          net.ipv4.tcp_mtu_probing: 1            # 10Gb/s | Jumbo frames
          net.ipv4.tcp_rmem: 4096 87380 33554432 # 10Gb/s
          net.ipv4.tcp_wmem: 4096 65536 33554432 # 10Gb/s
          net.ipv4.tcp_window_scaling: 1         # 10Gb/s
          # net.ipv4.tcp_tw_reuse: 1
          vm.nr_hugepages: 1024                  # PostgreSQL

    # Custom sysfs
    - |-
      machine:
        sysfs:
          devices.system.cpu.intel_pstate.hwp_dynamic_boost: 1
          devices.system.cpu.cpu0.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu1.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu2.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu3.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu4.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu5.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu6.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu7.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu8.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu9.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu10.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu11.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu12.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu13.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu14.cpufreq.energy_performance_preference: balance_performance
          devices.system.cpu.cpu15.cpufreq.energy_performance_preference: balance_performance

    # Various udev rules
    - |-
      machine:
        udev:
          rules:
            - KERNEL=="ttyUSB[0-9]", GROUP="20", MODE="0660"
            - # Intel GPU
              SUBSYSTEM=="drm", KERNEL=="renderD*", GROUP="44", MODE="0660"

    # Kernel configuration
    - |-
      machine:
        kernel:
          modules:
            - name: nbd

    # Cluster configuration
    - |-
      cluster:
        controllerManager:
          extraArgs:
            bind-address: 0.0.0.0
        proxy:
          disabled: true
        scheduler:
          extraArgs:
            bind-address: 0.0.0.0

    # Enable K8s Talos API Access
    - |-
      machine:
        features:
          rbac: true
          stableHostname: true
          kubernetesTalosAPIAccess:
            enabled: false
          apidCheckExtKeyUsage: true
          diskQuotaSupport: true
          hostDNS:
            enabled: true
            resolveMemberNames: true
            forwardKubeDNSToHost: false # Incompatible with Cilium bpf masquerade
