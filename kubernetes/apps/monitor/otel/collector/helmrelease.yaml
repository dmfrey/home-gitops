---
# yaml-language-server: $schema=https://kubernetes-schemas.dmfrey.com/helm.toolkit.fluxcd.io/helmrelease_v2beta2.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: otelcol-dm
spec:

  interval: 15m

  chart:
    spec:
      chart: opentelemetry-collector
      version: 0.101.0
      sourceRef:
        kind: HelmRepository
        name: opentelemetry-charts
        namespace: flux-system

  install:
    remediation:
      retries: 3

  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3

  uninstall:
    keepHistory: false

  values:

    mode: daemonset

    annotations:
      configmap.reloader.stakater.com/reload: otelcol-dm-opentelemetry-collector-agent

    image:
      repository: otel/opentelemetry-collector-contrib

    presets:
      # enables the k8sattributesprocessor and adds it to the traces, metrics, and logs pipelines
      kubernetesAttributes:
        enabled: true
        extractAllPodLabels: true
        extractAllPodAnnotations: true
      # enables the kubeletstatsreceiver and adds it to the metrics pipelines
      kubeletMetrics:
        enabled: true
      # Enables the filelogreceiver and adds it to the logs pipelines
      logsCollection:
        enabled: true
        includeCollectorLogs: true
        storeCheckpoints: true
      hostMetrics:
        enabled: true

    config:

      extensions:
        health_check: {}
        memory_ballast:
          size_in_percentage: 40

      processors:
        batch: {}
        memory_limiter:
          check_interval: 5s
          limit_percentage: 80
          spike_limit_percentage: 25
        resource:
          attributes:

            - action: insert
              key: loki.resource.labels
              value: service, k8s.pod.uid, k8s.pod.ip, k8s.pod.name, k8s.deployment.name, k8s.namespace.name, cluster, job, k8s.container.name, k8s.node.name

            - action: insert
              key: loki.format
              value: json

            - action: upsert
              key: service
              from_attribute: app.kubernetes.io/name

        resourcedetection:
          # Enriches telemetry data with resource information from the host
          detectors: ["env", "system"]
          override: false

      receivers:

        prometheus:
          config:
            global:
              scrape_interval: 15s # Adjust this interval as needed
            scrape_configs:
              - job_name: 'prometheus'
                static_configs:
                  - targets: ['kube-prometheus-stack-prometheus:9090'] # Adjust the Prometheus address and port

        # Data sources: traces, metrics, logs
        otlp:
          protocols:
            grpc:
              endpoint: 0.0.0.0:4317
            http:
              endpoint: 0.0.0.0:4318

        zipkin:
          endpoint: 0.0.0.0:9411

      exporters:

        # Data sources: traces, metrics, logs
        # NOTE: Prior to v0.86.0 use `logging` instead of `debug`
        debug:
          verbosity: detailed

        # Data sources: traces, metrics, logs
        otlp:
          endpoint: tempo-distributor.trace.svc.cluster.local:4317
          tls:
            insecure: true
          #   cert_file: cert.pem
          #   key_file: cert-key.pem

        # Data sources: traces, metrics
        loki:
          endpoint: http://loki-write-headless.logs.svc.cluster.local:3100/loki/api/v1/push
        otlphttp/tempo:
          endpoint: http://tempo-distributor.trace.svc.cluster.local:4318

        # Data sources: metrics
        # prometheus:
        #   endpoint: 0.0.0.0:8889
        #   namespace: default

        # Data sources: metrics
        prometheusremotewrite:
          endpoint: http://thanos-receive.monitor.svc.cluster.local:19291/api/v1/receive

        # Data sources: traces
        # zipkin:
        #   endpoint: http://tempo-distributor.trace.svc.cluster.local:9411/api/v2/spans

      connectors:
        spanmetrics:
          histogram:
            explicit:
              buckets: [100us, 1ms, 2ms, 6ms, 10ms, 100ms, 250ms]
          dimensions:
            - name: http.method       # extract http.method attribute from span to Prometheus label http_method
              default: GET
            - name: http.status_code  # extract http.status_code attribute from span to Prometheus label http_status_code
            - name: http.route        # extract http.route attribute from span to Prometheus label http_route
          exemplars:
            enabled: true
          exclude_dimensions: ['status.code']
          dimensions_cache_size: 1000
          aggregation_temporality: "AGGREGATION_TEMPORALITY_CUMULATIVE"
          metrics_flush_interval: 15s
          metrics_expiration: 5m
          events:
            enabled: true
            dimensions:
              - name: exception.type
              - name: exception.message
          resource_metrics_key_attributes:
            - service.name
            - telemetry.sdk.language
            - telemetry.sdk.name

      service:
        pipelines:
          traces:
            receivers: [ otlp, zipkin ]
            processors: [ memory_limiter, batch, resource, resourcedetection ]
            exporters: [ otlphttp/tempo, spanmetrics ]

          metrics:
            receivers: [ prometheus, spanmetrics ]
            processors: [ memory_limiter, batch, resource, resourcedetection ]
            exporters: [ prometheusremotewrite ]

          logs:
            receivers: [ filelog ]
            processors: [ memory_limiter, batch, resource, resourcedetection ]
            exporters: [ loki ]

    service:
      enabled: true
      type: ClusterIP
---
# yaml-language-server: $schema=https://kubernetes-schemas.dmfrey.com/helm.toolkit.fluxcd.io/helmrelease_v2beta2.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: otelcol-dp
spec:

  interval: 15m

  chart:
    spec:
      chart: opentelemetry-collector
      version: 0.101.0
      sourceRef:
        kind: HelmRepository
        name: opentelemetry-charts
        namespace: flux-system

  install:
    remediation:
      retries: 3

  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3

  uninstall:
    keepHistory: false

  values:

    mode: deployment

    replicaCount: 1

    annotations:
      configmap.reloader.stakater.com/reload: otelcol-dp-opentelemetry-collector-agent

    image:
      repository: otel/opentelemetry-collector-contrib

    presets:
      # enables the k8sclusterreceiver and adds it to the metrics pipelines
      clusterMetrics:
        enabled: true
      # enables the k8sobjectsreceiver to collect events only and adds it to the logs pipelines
      kubernetesEvents:
        enabled: true

    config:

      extensions:
        health_check: {}
        memory_ballast:
          size_in_percentage: 40

      processors:
        batch: {}
        memory_limiter:
          check_interval: 5s
          limit_percentage: 80
          spike_limit_percentage: 25

      receivers:

        prometheus:
          config:
            global:
              scrape_interval: 15s # Adjust this interval as needed
            scrape_configs:
              - job_name: 'prometheus'
                static_configs:
                  - targets: ['kube-prometheus-stack-prometheus:9090'] # Adjust the Prometheus address and port

        # Data sources: traces, metrics, logs
        otlp:
          protocols:
            grpc:
              endpoint: 0.0.0.0:4317
            http:
              endpoint: 0.0.0.0:4318

        zipkin:
          endpoint: 0.0.0.0:9411

      exporters:

        # Data sources: traces, metrics, logs
        # NOTE: Prior to v0.86.0 use `logging` instead of `debug`
        debug:
          verbosity: detailed

        # Data sources: traces, metrics, logs
        otlp:
          endpoint: tempo-distributor.trace.svc.cluster.local:4317
          tls:
            insecure: true

        # Data sources: traces, metrics
        loki:
          endpoint: http://loki-write-headless.logs.svc.cluster.local:3100/loki/api/v1/push
        otlphttp/tempo:
          endpoint: http://tempo-distributor.trace.svc.cluster.local:4318

        # Data sources: metrics
        prometheusremotewrite:
          endpoint: http://thanos-receive.monitor.svc.cluster.local:19291/api/v1/receive

      service:
        pipelines:
          metrics:
            receivers: [ prometheus ]
            processors: [ memory_limiter, batch ]
            exporters: [ prometheusremotewrite ]

          # logs:
          #   # receivers: [ otlp ]
          #   processors: [ memory_limiter, batch ]
          #   exporters: [ loki ]

    service:
      enabled: true
      type: ClusterIP
